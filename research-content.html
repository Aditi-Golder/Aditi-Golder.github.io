<section id="research">
    <h2>Research</h2>
  
    <!-- Lab Information -->
    <div class="lab-info">
      <h3>Current Lab</h3>
      <p>Currently working under the <a href="https://irsc-wfu.github.io/" target="_blank">Intelligent Remote Sensing and Computing (IRSC) Lab</a> at Wake Forest University, supervised by <a href="https://paucavp.sites.wfu.edu/" target="_blank">Dr. V. Paúl Pauca</a>. IRSC lab is an interdisciplinary group of researchers from Wake Forest’s Biology and Computer Science departments in collaboration with researchers and conservationists at Dartmouth College and <a href="https://cincia.wfu.edu/en/" target="_blank">The Center for Amazonian Scientific Innovation</a> in Peru. Our lab works on methods to apply machine learning, artificial intelligence, and statistics to the problems of conservation in the Peruvian Amazon and around the world.</p>
    </div>

<!-- Advisor Section -->
    <div class="advisors">
        <h3>Advisors</h3>
        <div class="advisor-grid">
      
          <div class="advisor-card">
            <img src="figures/paul-pauca.jpg" alt="Dr. V. Paúl Pauca">
            <div>
              <strong><a href="https://paucavp.sites.wfu.edu/" target="_blank">Dr. V. Paúl Pauca</a></strong><br/>
              Professor, Department of Computer Science<br/>
              Wake Forest University, NC, USA
            </div>
          </div>
      
          <div class="advisor-card">
            <img src="figures/akkas.jpg" alt="Dr. KM Akkas Ali">
            <div>
              <strong><a href="https://juniv.edu/teachers/akkas" target="_blank">Dr. KM Akkas Ali</a></strong><br/>
              Professor, Institute of Information Technology<br/>
              Jahangirnagar University, Dhaka, Bangladesh
            </div>
          </div>
      
          <div class="advisor-card">
            <img src="figures/nusrat.jpeg" alt="Dr. Nusrat Jahan">
            <div>
              <strong><a href="https://faculty.daffodilvarsity.edu.bd/profile/swe/nusrat-jahan.html" target="_blank">Dr. Nusrat Jahan</strong></a><br/>
              Assistant Professor, Department of Software Engineering<br/>
              Daffodil International University, Dhaka, Bangladesh
            </div>
          </div>
      
        </div>
      </div>
       
   <!-- Collaborators Section -->
<div class="collaborators">
    <h3>Collaborators</h3>
    <div class="collab-grid">
  
      <div class="collab-card">
        <img src="figures/zeyarAung.jpg" alt="Dr. U Zeyar Aung">
        <div>
          <strong><a href="https://www.ku.ac.ae/college-people/zeyar-aung" target="_blank">Dr. U Zeyar Aung</strong></a><br>
          Associate Professor<br>
          Department of Computer Science<br>
          Khalifa University, Abu Dhabi, UAE
        </div>
      </div>
  
      <div class="collab-card">
        <img src="figures/moni.jpeg" alt="Dr. Mohammad Ali Moni">
        <div>
          <strong><a href="https://about.uq.edu.au/experts/32270" target="_blank">Dr. Mohammad Ali Moni</a></strong><br>
          Research Fellow<br>
          Faculty of Medicine, UNSW Sydney<br>
          The Garvan Institute of Medical Research
        </div>
      </div>
  
      <div class="collab-card">
        <img src="figures/kishor.png" alt="Dr. Kishor Datta Gupta">
        <div>
          <strong><a href="https://www.kishordgupta.com/" target="_blank">Dr. Kishor Datta Gupta</strong></a><br>
          Assistant Professor<br>
          Department of Computer Science<br>
          Clark Atlanta University, GA, USA
        </div>
      </div>
  
      <div class="collab-card">
        <img src="figures/dipankar.jpg" alt="Dr. Dipankar Dasgupta">
        <div>
          <strong><a href="https://www.memphis.edu/cs/dasgupta/" target="_blank">Dr. Dipankar Dasgupta</strong></a><br>
          Hill Professor<br>
          Department of Computer Science<br>
          The University of Memphis, TN, USA
        </div>
      </div>
  
      <div class="collab-card">
        <img src="figures/george.jpeg" alt="Dr. Roy George">
        <div>
            <strong><a href="https://www.linkedin.com/in/dr-roy-george-3a039618/" target="_blank">Dr. Roy George</strong></a><br>
          <br>
          Chair<br>
          Department of Cyber-Physical Systems<br>
          Clark Atlanta University, GA, USA
        </div>
      </div>
  
      <div class="collab-card">
        <img src="figures/khalil.jpg" alt="Dr. Khalil Shujaee">
        <div>
          <strong><a href="https://ieeexplore.ieee.org/author/37297148300" target="_blank">Dr. Khalil Shujaee</strong></a><br>
          Professor<br>
          Department of Computer Science<br>
          Clark Atlanta University, GA, USA
        </div>
      </div>
  
      <div class="collab-card">
        <img src="figures/sarra.jpg" alt="Dr. Sarra Alqahtani">
        <div>
          <strong><a href="https://alqahtas.sites.wfu.edu/" target="_blank">Dr. Sarra Alqahtani</strong></a><br>
          Associate Professor<br>
          Department of Computer Science<br>
          Wake Forest University, NC, USA
        </div>
      </div>
  
      <div class="collab-card">
        <img src="figures/silman.jpeg" alt="Dr. Miles R. Silman">
        <div>
          <strong><a href="https://biology.wfu.edu/faculty-research/miles-silman/" target"_blank">Dr. Miles R. Silman</strong></a><br>
          <br>
          Andrew Sabin Professor of Conservation Biology<br>
          Wake Forest University, NC, USA<br>
        </div>
      </div>
  
      <div class="collab-card">
        <img src="figures/kangning.jpeg" alt="Dr. Kangning Cui">
        <div>
          <strong><a href="https://ckn3.github.io/" target="_blank">Dr. Kangning Cui</strong></a><br>
          Research Assistant Professor<br>
          Department of Computer Science<br>
          Wake Forest University, NC, USA
        </div>
      </div>
  
      <div class="collab-card">
        <img src="figures/debashis.jpeg" alt="Debashis Gupta">
        <div>
          <strong><a href="https://debashis-gupta.github.io/AcademicWebsite/" target="_blank">Debashis Gupta</strong></a><br>
          PhD Fellow<br>
          Department of Biomedical Engineering<br>
          Wake Forest School of Medicine, NC, USA
        </div>
      </div>

      <div class="collab-card">
        <img src="figures/saumendu.jpeg" alt="Saumendu Roy">
        <div>
          <strong><a href="https://ca.linkedin.com/in/saumendu-roy-b62a662a0" target="_blank">Saumendu Roy</strong></a><br>
          PhD Fellow<br>
          Department of Computer Science<br>
          University of Saskatchewan, Saskatoon, Canada
        </div>
      </div>

      <div class="collab-card">
        <img src="figures/ariful.jpeg" alt="Mohd Ariful Haque">
        <div>
        <strong><a href="https://ariful-haque.com//" target="_blank">Mohd Ariful Haque</strong></a><br>
          PhD Fellow<br>
          Department of Cyber-Physical Systems<br>
          Clark Atlanta University, GA, USA
        </div>
      </div>
  
    </div>
  </div>
  
  
<!-- Research Projects Heading -->
   <h3 class="research-heading">Research Projects</h3>

<!-- === Project 1 === -->
<div class="project-block">
  <div class="project-header" onclick="toggleDetails(this)">
    <div class="project-info">
      <h4 class="project-title">
        MoSAiC: Multi-Modal Multi-Label Supervision-Aware Contrastive Learning for Remote Sensing
      </h4>
    </div>
    <div class="toggle-icon" title="Expand">▼</div>
  </div>
  <div class="project-details">
    <div class="project-layout">
      <img src="figures/workflow.JPG" alt="MoSAiC Architecture" class="project-arch">
      <div class="project-meta-box">
        <p class="project-meta">
          <strong>Submitted to AAAI, 2026</strong> <br/>
          <!-- Impact Factor: 3.880<br/> -->
          <a href="https://arxiv.org/abs/2507.08683" target="_blank">[Preprint]</a>
        </p>
        <p>
          Contrastive learning (CL) has emerged as a powerful paradigm for learning transferable representations without the reliance on large labeled datasets. Its ability to capture intrinsic similarities and differences among data samples has led to state-of-the-art results in computer vision tasks. These strengths make CL particularly well-suited for Earth System Observation (ESO), where diverse satellite modalities such as optical and SAR imagery offer naturally aligned views of the same geospatial regions. However, ESO presents unique challenges, including high inter-class similarity, scene clutter, and ambiguous boundaries, which complicate representation learning especially in low-label, multi-label settings. Existing CL frameworks often focus on intra-modality self-supervision or lack mechanisms for multi-label alignment and semantic precision across modalities. 
          In this work, we introduce MoSAiC, a unified framework that jointly optimizes intra- and inter-modality contrastive learning with a multi-label supervised contrastive loss. Designed specifically for multi-modal satellite imagery, MoSAiC enables finer semantic disentanglement and more robust representation learning across spectrally similar and spatially complex classes. Experiments on two benchmark datasets, BigEarthNet V2.0 and Sent12MS, show that MoSAiC consistently outperforms both fully supervised and self-supervised baselines in terms of accuracy, cluster coherence, and generalization in low-label and high-class-overlap scenarios.
        </p>
      </div>
    </div>
  </div>
</div>

<!-- === Project 2 === -->
<div class="project-block">
  <div class="project-header" onclick="toggleDetails(this)">
    <div class="project-info">
      <h4 class="project-title">
        Scalable Knowledge Graph Construction from Unstructured Text: A Case Study on Artisanal and Small-Scale Gold Mining
      </h4>
    </div>
    <div class="toggle-icon" title="Expand">▼</div>
  </div>
  <div class="project-details">
    <div class="project-layout">
      <img src="figures/kg.png" alt="Leukemia Project Architecture" class="project-arch">
      <div class="project-meta-box">
        <p class="project-meta">
          <strong>Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)</strong><br/>
          <a href="https://doi.org/10.1007/978-981-96-8173-0_37" target="_blank">[DOI: https://doi.org/10.1007/978-981-96-8173-0_37]</a>
        </p>
        <p>
          Constructing knowledge graphs (KGs) from unstructured text is an important yet challenging task, often requiring a great deal of manual effort and domain-specific adjustments. We propose an unsupervised, scalable method that automates both triplet extraction (subject, predicate, object) and validation using large language models (LLMs). Our framework leverages PageRank to rank external knowledge sources from the web, which are provided as contextual input to multiple LLM queries. Majority voting is then performed in the output space of these queries to ensure relationship validation. This approach offers a generalizable, domain-agnostic solution for KG construction across diverse fields. As a case study, we applied the method to Artisanal and Small-Scale Gold Mining (ASGM), constructing a knowledge graph from 1,899 triplets extracted from 9 domain-specific documents, cumulatively amounting to approximately 930 pages of unstructured text. Our framework achieves comparable performance with five baselines on a publicly available KG benchmark, and achieves over 
          accuracy on ASGM-KG, as validated by domain experts. Additionally, our framework was able to identify factual inaccuracies in popular benchmarks like Codex, highlighting the need for more reliable validation methods.
      </div>
    </div>
  </div>
</div>

<!-- === Project 3 === -->
<div class="project-block">
    <div class="project-header" onclick="toggleDetails(this)">
      <div class="project-info">
        <h4 class="project-title">
          CervixMed: Detecting Cervical Cancer based on combinational data using Hybrid architecture
        </h4>
      </div>
      <div class="toggle-icon" title="Expand">▼</div>
    </div>
    <div class="project-details">
      <div class="project-layout">
        <img src="figures/gui_cervix.png" alt="MoSAiC Architecture" class="project-arch">
        <div class="project-meta-box">
          <p class="project-meta">
            <strong>2023 International Conference on Digital Image Computing: Techniques and Applications (DICTA)</strong> <br/>
            <!-- Impact Factor: 3.880<br/> -->
            <a href="https://doi.org/10.1109/DICTA60407.2023.00085" target="_blank">[DOI: 10.1109/DICTA60407.2023.00085]</a>
          </p>
          <p>
            Cervical cancer is women’s second most frequent malignancy globally, with a 60% mortality rate. Early identification through routine checkups is crucial because cervical cancer has a long latent period and begins with no overt signs. One of the most evident barriers to not having an early detection is the time required for the diagnostic process, which also accounts for indifference regarding its automation. These uncertainties occur for several reasons, while one of the most prominent causes is providing the report by the computer-aided diagnostic process only based on the patient’s information in tabular form or only predicting the patient’s cervix image. In this study, we proposed three concepts 1. Hybrid Architecture, 2. CervixMed, a novel CNN-based architecture, and 3. GUI (Graphical User Interface). In Hybrid Architecture, we propose a methodology that takes both types of data, i.e., tabular and image, and then merges the prediction provided by the models and shows the final output. For tabular data classification, we use traditional-machine learning models like KNN, SVM, LR, and RF, where LR and SVM provided the best accuracy of 99%. On the other hand, the image data is classified into one of the five categories using our novel lightweight CNN-based architecture, CervixMed, that outperforms other pre-trained models like DenseNet121, DenseNet169, DenseNet201, ResNetl52v2, and VGG19 by 94% in accuracy and 98% in sensitivity. The hybrid architecture combines the abovementioned models and chooses the best pair regarding accuracy.
            In this study, we demonstrated that combining LR and SVM with CervixMed outperforms the other combinations by 96.5% accuracy. Lastly, we demonstrated the methodology of the proposed GUI for interacting with the end-users with this hybrid model.
        </div>
      </div>
    </div>
  </div>

<!-- === Project 4 === -->
  <div class="project-block">
  <div class="project-header" onclick="toggleDetails(this)">
    <div class="project-info">
      <h4 class="project-title">
        Development of Automatic Number Plate Recognition System of Bangladeshi Vehicle Using Object Detection and OCR
      </h4>
    </div>
    <div class="toggle-icon" title="Expand">▼</div>
  </div>
  <div class="project-details">
    <div class="project-layout">
      <img src="figures/number_plate_recognition.png" alt="Leukemia Project Architecture" class="project-arch">
      <div class="project-meta-box">
        <p class="project-meta">
          <strong>International Conference on Advances in Data-driven Computing and Intelligent Systems</strong><br/>
          <a href="https://doi.org/10.1007/978-981-99-9524-0_25" target="_blank">[DOI: https://doi.org/10.1007/978-981-99-9524-0_25]</a>
        </p>
        <p>
          The traffic issue in Bangladesh is one of the strongest and most demanding issues in city surveillance today. Finding and separating automobiles on the side of the road and in the parking lot has become more crucial as Bangladesh’s traffic congestion problem worsens at an alarming rate. 
          There is now a lot of study being done on the topic of object detection and classification. The detection of vehicles and the recognition of license plates have been the subject of numerous studies. But there are still certain restrictions. Locating the double-row number plate accurately is one of them. In this study, we proposed a technique for locating both single-row and double-row license plates as well as detecting the vehicle type. The suggested model, YOLOv4 and OCR (optical character recognition) Tesseract can be utilized to create a real-time system and has good accuracy and inference time for a variety of illumination and style of Bangladeshi number plates. The model showed a mAP value of almost 97%, and the other evaluation metrics performance is also acceptable. Our proposed model outperformed the prior system.
        </p>
      </div>
    </div>
  </div>
</div>

<!-- === Project 5 === -->
<div class="project-block">
  <div class="project-header" onclick="toggleDetails(this)">
    <div class="project-info">
      <h4 class="project-title">
        Prediction of Heart Disease and Heart Failure Using Ensemble Machine Learning Models
      </h4>
    </div>
    <div class="toggle-icon" title="Expand">▼</div>
  </div>
  <div class="project-details">
    <div class="project-layout">
      <img src="figures/kg.png" alt="Leukemia Project Architecture" class="project-arch">
      <div class="project-meta-box">
        <p class="project-meta">
          <strong>Preprint.org</strong><br/>
          <a href="https://example.com/leukemia-paper" target="_blank">[Preprint Link]</a>
        </p>
        <p>
          This project explores a weighted ensemble of CNNs for classifying ALL (acute lymphoblastic leukemia) from microscopic images. It enhances robustness through fusion of multiple models trained on balanced and augmented samples.
        </p>
      </div>
    </div>
  </div>
</div>

<!-- === Project 6 === -->
<div class="project-block">
  <div class="project-header" onclick="toggleDetails(this)">
    <div class="project-info">
      <h4 class="project-title">
        Automated Railway Crossing System: A Secure and Resilient Approach
      </h4>
    </div>
    <div class="toggle-icon" title="Expand">▼</div>
  </div>
  <div class="project-details">
    <div class="project-layout">
      <img src="figures/kg.png" alt="Leukemia Project Architecture" class="project-arch">
      <div class="project-meta-box">
        <p class="project-meta">
          <strong>Preprint.org</strong><br/>
          <a href="https://example.com/leukemia-paper" target="_blank">[Preprint Link]</a>
        </p>
        <p>
          This project explores a weighted ensemble of CNNs for classifying ALL (acute lymphoblastic leukemia) from microscopic images. It enhances robustness through fusion of multiple models trained on balanced and augmented samples.
        </p>
      </div>
    </div>
  </div>
</div>

<!-- === Project 7 === -->
<div class="project-block">
  <div class="project-header" onclick="toggleDetails(this)">
    <div class="project-info">
      <h4 class="project-title">
       GSM Based Home Security Alarm System Using Arduino Using Mobile Call
      </h4>
    </div>
    <div class="toggle-icon" title="Expand">▼</div>
  </div>
  <div class="project-details">
    <div class="project-layout">
      <img src="figures/kg.png" alt="Leukemia Project Architecture" class="project-arch">
      <div class="project-meta-box">
        <p class="project-meta">
          <strong>Preprint.org</strong><br/>
          <a href="https://example.com/leukemia-paper" target="_blank">[Preprint Link]</a>
        </p>
        <p>
          This project explores a weighted ensemble of CNNs for classifying ALL (acute lymphoblastic leukemia) from microscopic images. It enhances robustness through fusion of multiple models trained on balanced and augmented samples.
        </p>
      </div>
    </div>
  </div>
</div>

<!-- === Project 8 === -->
<div class="project-block">
  <div class="project-header" onclick="toggleDetails(this)">
    <div class="project-info">
      <h4 class="project-title">
        EmoBang: Detecting Emotion From Bengali Texts
      </h4>
    </div>
    <div class="toggle-icon" title="Expand">▼</div>
  </div>
  <div class="project-details">
    <div class="project-layout">
      <img src="figures/kg.png" alt="Leukemia Project Architecture" class="project-arch">
      <div class="project-meta-box">
        <p class="project-meta">
          <strong>Preprint.org</strong><br/>
          <a href="https://example.com/leukemia-paper" target="_blank">[Preprint Link]</a>
        </p>
        <p>
          This project explores a weighted ensemble of CNNs for classifying ALL (acute lymphoblastic leukemia) from microscopic images. It enhances robustness through fusion of multiple models trained on balanced and augmented samples.
        </p>
      </div>
    </div>
  </div>
</div>

  <p>See my complete profile on <a href="https://scholar.google.com/citations?user=_ksO_SgAAAAJ" target="_blank">Google Scholar</a>.</p>
</section>

      

    
              
